@article{boerProofTheoryAsynchronously2001,
  title = {A {{Proof Theory}} of {{Asynchronously Communicating Sequential Processes}}},
  author = {Boer, Es and Francez, Nissim and Hutst, Van and Stomp, Fa},
  year = {2001},
  month = sep,
  abstract = {We present compositional Hoare logics for distributed systems in which communication is asynchronous via FIFO channels. The logics are proved sound and relative complete.}
}

@book{brazhukSecurityPatternsBased2020,
  title = {Security Patterns Based Approach to Automatically Select Mitigations in Ontology-Driven Threat Modelling},
  author = {Brazhuk, Andrei},
  year = {2020},
  month = feb,
  abstract = {Common approach of the threat modelling includes an analysis of computer system architecture on early stages of development process and creation of threat model. Data Flow Diagrams (DFD) are often used to represent the system organization. The main challenge with threat modelling is that there are no formal approaches to describe the computer system architecture and structured knowledge sources of threats and countermeasures. To overcome these restrictions we have created ontology-driven threat modelling (OdTM) framework based on base threat model, used to develop various domain-specific threat models. Each domain-specific threat model contains a set of typical components of some architectural domain, threats and countermeasures. A system architect describes its computer system with DFD diagram; then automatic reasoning procedures are used to semantically interpret the diagram and figure out relevant threats and countermeasures for the system. We approach a conception of context security patterns as countermeasures. Context security pattern contains a precise description of security problem and its solution. Also it has criteria that allow to automatically map it to system component. We propose three ways to integrate context security patterns with domain-specific threat models: with data flow templates, through association with threats, and the use of labels. All the models, discussed in this work, can be implemented as OWL (Web Ontology Language) ontologies with Description logics (DL) as a mathematical background.}
}

@inproceedings{buthCombiningMethodsLivelock1999,
  title = {Combining {{Methods}} for the {{Livelock Analysis}} of a {{Fault-Tolerant System}}},
  booktitle = {Algebraic {{Methodology}} and {{Software Technology}}},
  author = {Buth, Bettina and Peleska, Jan and Shi, Hui},
  editor = {Haeberer, Armando M.},
  year = {1999},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {124--139},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/3-540-49253-4_11},
  abstract = {This article presents experiences gained from the verification of communication properties of a large-scale real-world embedded system by means of formal methods. This industrial verification project was performed for a fault-tolerant system designed and implemented by Daimler-Benz Aerospace for the International Space Station ISS and focused essentially on deadlock and livelock analysis. The approach is based on CSP specifications and the model-checking tool FDR. The tasks are split into manageable subtasks by applying abstraction techniques for restricting the specifications to the essential communication behavior, modularization according to the process structure, and a set of generic theories developed for the application.},
  isbn = {978-3-540-49253-5},
  langid = {english},
  keywords = {Communication Behavior,Communication Graph,International Space Station,Model Check,Proof Obligation}
}

@inproceedings{buthDeadlockAnalysisFaulttolerant1997,
  title = {Deadlock Analysis for a Fault-Tolerant System},
  booktitle = {Algebraic {{Methodology}} and {{Software Technology}}},
  author = {Buth, Bettina and Kouvaras, Michel and Peleska, Jan and Shi, Hui},
  editor = {Johnson, Michael},
  year = {1997},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {60--74},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/BFb0000463},
  abstract = {This article presents an approach for the verification of communication properties in large-scale real-world embedded systems by means of formal methods. It is illustrated by examples and results obtained during an industrial verification project performed for a fault-tolerant system designed and implemented by Daimler-Benz Aerospace for the International Space Station ISS. The approach is based on CSP specifications and the model-checking tool FDR. The task is split into manageable subtasks by applying an abstraction technique for restricting the specifications to the essential communication behaviour, modularization according to the process structure, and a set of generic theories developed for the application.},
  isbn = {978-3-540-69661-2},
  langid = {english},
  keywords = {Communication Behaviour,Deadlock Situation,Input Channel,Model Checker,Proof Obligation}
}

@article{casanovasSemanticWebLegal2016,
  title = {Semantic {{Web}} for the {{Legal Domain}}: {{The}}\&nbsp;next Step},
  shorttitle = {Semantic {{Web}} for the {{Legal Domain}}},
  author = {Casanovas, Pompeu and Palmirani, Monica and Peroni, Silvio and {van Engers}, Tom and Vitali, Fabio},
  year = {2016},
  month = jan,
  journal = {Semantic Web},
  volume = {7},
  number = {3},
  pages = {213--227},
  publisher = {{IOS Press}},
  issn = {1570-0844},
  doi = {10.3233/SW-160224},
  abstract = {Ontology-driven systems with reasoning capabilities in the legal field are now better understood. Legal concepts are not discrete, but make up a dynamic continuum between common sense terms, specific technical use, and professional knowledge, in an e},
  langid = {english}
}

@misc{CEFEDeliveryBuilding2016,
  title = {{{CEF eDelivery Building Block Security Controls}} Guidance},
  year = {2016},
  month = jun,
  url = {https://ec.europa.eu/cefdigital/wiki/cefdigital/wiki/display/CEFDIGITAL/Security+Controls+guidance},
  urldate = {2021-07-02},
  abstract = {The 'Security Controls' guidance document addresses the security controls and recommendations applicable to CEF eDelivery's message exchange Use Case.},
  langid = {english}
}

@misc{cicirielloPEPPOLTransportInfrastructure2011,
  title = {{{PEPPOL Transport Infrastructure Technical Overview}}},
  author = {Ciciriello, Carmen and Andersen, Jens and Bengtsson, Kenneth},
  year = {2011},
  month = nov,
  url = {https://www.galaxygw.com/wp-content/uploads/openpeppol/20111122-peppol-transport-infrastructure-v1.17.pdf},
  urldate = {2021-07-02},
  abstract = {The purpose of this document is to provide interested organisations with a deeper understanding of the PEPPOL Transport Infrastructure, its key features, components and governance}
}

@article{costaAccessControlWeakly2016,
  title = {Access {{Control}} in {{Weakly Consistent Systems}}},
  author = {da Costa, Tiago Miguel Ferreira},
  year = {2016},
  month = dec,
  url = {https://run.unl.pt/handle/10362/30066},
  urldate = {2021-09-27},
  abstract = {Eventually consistent models have become popular in the last years in data storage  systems for cloud environments, allowing to give users better availability and lower  latency. In this model, it is possible for replicas to be temporarily inconsistent, having  been proposed various solutions to deal with this inconsistency and ensure the final  convergence of data. However, defining and enforcing access control policies under this model is still an open challenge.  The implementation of access control policies for these systems raises it's own challenges, given the information about the permissions is itself kept in a weakly consistent form. In this dissertation, a solution for this problem is proposed, that allows to prevent the non authorized access and modification of data.  The proposed solution allows concurrent modifications on the security policies, ensuring their convergence when they are used to verify and enforce access control the associated data. In this dissertation we present an evaluation of the proposed model, showing the solution respects the correct functioning over possible challenging situations, also discussing its application on scenarios that feature peer-to-peer communication between clients and additional replicas on the clients, with the goal of providing a lower latency and reduce the load on centralized components.},
  copyright = {openAccess},
  langid = {english},
  annotation = {Accepted: 2018-02-08T11:46:42Z}
}

@misc{CyberThreatUK2018,
  title = {The Cyber Threat to {{UK}} Legal Sector},
  year = {2018},
  month = jul,
  publisher = {{National Cyber Security Centre}},
  url = {https://www.ncsc.gov.uk/report/-the-cyber-threat-to-uk-legal-sector--2018-report},
  urldate = {2021-07-20},
  abstract = {A new report from the NCSC explaining how UK law firms - of all sizes - can protect themselves from common cyber threats.},
  langid = {english}
}

@misc{ettlingCloudBiggestThreat2015,
  title = {The {{Cloud}}'s {{Biggest Threat Are Data Sovereignty Laws}}},
  author = {Ettling, Mike},
  year = {2015},
  month = dec,
  journal = {TechCrunch},
  url = {https://social.techcrunch.com/2015/12/26/the-clouds-biggest-threat-are-data-sovereignty-laws/},
  urldate = {2021-07-16},
  abstract = {The beauty of the cloud is the promise of simplification and standardization -- without regard to physical or geographic boundaries. It's this ``any time, any place, any device'' flexibility that is driving rapid adoption. However, new government regulations on data sovereignty threaten to complicate\ldots},
  langid = {american}
}

@misc{franzThreePartsSecurity,
  title = {The {{Three Parts}} of {{Security}}},
  author = {Franz, Bill},
  url = {http://erights.org/elib/capability/3parts.html},
  urldate = {2021-06-29}
}

@book{freundMeasuringManagingInformation2014,
  title = {Measuring and {{Managing Information Risk}}: {{A FAIR Approach}}},
  shorttitle = {Measuring and {{Managing Information Risk}}},
  author = {Freund, Jack and Jones, Jack},
  year = {2014},
  month = aug,
  publisher = {{Butterworth-Heinemann}},
  abstract = {Using the factor analysis of information risk (FAIR) methodology developed over ten years and adopted by corporations worldwide, Measuring and Managing Information Risk provides a proven and credible framework for understanding, measuring, and analyzing information risk of any size or complexity. Intended for organizations that need to either build a risk management program from the ground up or strengthen an existing one, this book provides a unique and fresh perspective on how to do a basic quantitative risk analysis. Covering such key areas as risk theory, risk calculation, scenario modeling, and communicating risk within the organization, Measuring and Managing Information Risk helps managers make better business decisions by understanding their organizational risk.Uses factor analysis of information risk (FAIR) as a methodology for measuring and managing risk in any organization.Carefully balances theory with practical applicability and relevant stories of successful implementation.Includes examples from a wide variety of businesses and situations presented in an accessible writing style.},
  googlebooks = {oAR0AwAAQBAJ},
  isbn = {978-0-12-799932-6},
  langid = {english},
  keywords = {Business \& Economics / Information Management,Computers / Security / General}
}

@article{gharibCOPriCoreOntology2021,
  title = {{{COPri}} v.2 \textemdash{} {{A}} Core Ontology for Privacy Requirements},
  author = {Gharib, Mohamad and Giorgini, Paolo and Mylopoulos, John},
  year = {2021},
  month = may,
  journal = {Data \& Knowledge Engineering},
  volume = {133},
  pages = {101888},
  issn = {0169-023X},
  doi = {10.1016/j.datak.2021.101888},
  abstract = {Nowadays, most enterprises collect, store, and manage personal information of customers to deliver their services. In such a setting, privacy has emerged as a key concern since companies often neglect or even misuse personal data. In response to multiple massive breaches of personal data, governments around the world have enacted laws and regulations for privacy protection. These laws dictate privacy requirements for any system that acquires and manages personal data. Unfortunately, these requirements are often incomplete and/or inaccurate as many RE practitioners are insufficiently versed with privacy requirements and how are they different from other requirements, such as security. To tackle this problem, we developed a comprehensive ontology for privacy requirements. In particular, the contributions of this work include the derivation of an ontology from a previously conducted systematic literature review, an implementation using an ontology definition tool (Prot\'eg\'e), a demonstration of its coverage through an extensive example on Ambient Assisted Living, and a validation through competency questions. Also, we evaluate the ontology against the common pitfalls for ontologies with the help of some software tools, lexical semantics experts, and privacy and security researchers. The ontology presented herein (COPri v.2) has been enhanced with extensions motivated by the feedback received from privacy and security experts.},
  langid = {english},
  keywords = {Conceptual modeling,PbD,Privacy by Design,Privacy ontology,Privacy requirements,Requirements engineering}
}

@article{hellersteinKeepingCALMWhen2019,
  title = {Keeping {{CALM}}: {{When Distributed Consistency}} Is {{Easy}}},
  shorttitle = {Keeping {{CALM}}},
  author = {Hellerstein, Joseph M. and Alvaro, Peter},
  year = {2019},
  month = jan,
  journal = {arXiv:1901.01930 [cs]},
  eprint = {1901.01930},
  eprinttype = {arxiv},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/1901.01930},
  urldate = {2021-08-11},
  abstract = {A key concern in modern distributed systems is to avoid the cost of coordination while maintaining consistent semantics. Until recently, there was no answer to the question of when coordination is actually required. In this paper we present an informal introduction to the CALM Theorem, which answers this question precisely by moving up from traditional storage consistency to consider properties of programs. CALM is an acronym for "consistency as logical monotonicity". The CALM Theorem shows that the programs that have consistent, coordination-free distributed implementations are exactly the programs that can be expressed in monotonic logic. This theoretical result has practical implications for developers of distributed applications. We show how CALM provides a constructive application-level counterpart to conventional "systems" wisdom, such as the apparently negative results of the CAP Theorem. We also discuss ways that monotonic thinking can influence distributed systems design, and how new programming language designs and tools can help developers write consistent, coordination-free code.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Databases,Computer Science - Distributed; Parallel; and Cluster Computing,Computer Science - Programming Languages,Computer Science - Software Engineering}
}

@misc{hermanRDFGraphLiterals2010,
  title = {{{RDF Graph Literals}} and {{Named Graphs}}},
  author = {Herman, Ivan},
  year = {2010},
  month = feb,
  url = {https://www.w3.org/2009/07/NamedGraph.html},
  urldate = {2022-01-19},
  abstract = {This document introduces a formal semantics for (RDF) Graph Literals and Named Graphs. Graph Literals allow applications to make statements on triples (eg, provenance) without really asserting them, ie, without ensuring their existence. Named Graphs makes it possible to assign a URI to a collection of triples, and being able to make statements on the whole set (in some ways, the URI of an RDF/XML file that contains a number of triples can be considered to be a Named Graph).}
}

@book{hoareCommunicatingSequentialProcesses2015,
  title = {Communicating {{Sequential Processes}}},
  author = {Hoare, C A R},
  year = {2015},
  month = may,
  url = {http://www.usingcsp.com/cspbook.pdf},
  copyright = {\textcopyright{} C. A. R. Hoare, 1985\textendash 2004},
  langid = {english}
}

@article{ibanezLiveLinkedData2013,
  title = {Live Linked Data: Synchronising Semantic Stores with Commutative Replicated Data Types},
  shorttitle = {Live Linked Data},
  author = {Ib{\'a}{\~n}ez, Luis-Daniel and {Skaf-Molli}, Hala and Molli, Pascal and Corby, Olivier},
  year = {2013},
  month = jan,
  journal = {International Journal of Metadata, Semantics and Ontologies},
  volume = {8},
  number = {2},
  pages = {119--133},
  publisher = {{Inderscience Publishers}},
  issn = {1744-2621},
  doi = {10.1504/IJMSO.2013.056605},
  abstract = {Linked Data is currently interconnecting information on the web, creating the web of data. It allows data consumers to combine different data sets and perform powerful queries. However, this means either to copy data sets locally or perform distributed querying. Local copies have problems of freshness, distributed queries, of scalability and performance. Linked Data producers are currently going live by providing streams of data updates, opening a third way to query: synchronise and search. Each Linked Data node can follow update streams of others, creating a social network of live updates: the Live Linked Data (LLD). Unfortunately, synchronising data among autonomous participants raises issues of concurrency and consistency. In this paper, we propose SU-Set, a Commutative Replicated Data Type (CRDT) for RDF graph updated with SPARQL Update 1.1. We describe how a semantic store can use SU-Set to ensure eventual consistency in LLD, with a low overhead in time, space and communication.}
}

@misc{jagannathanAdvancedThreatModelling2012,
  title = {Advanced {{Threat Modelling Knowledge Session}}},
  author = {Jagannathan, Venkatesh},
  year = {2012},
  month = aug,
  url = {https://owasp.org/www-pdf-archive/AdvancedThreatModeling.pdf},
  urldate = {2021-06-19},
  langid = {english}
}

@misc{kleppmannAdaptingSecureGroup2019,
  title = {Adapting Secure Group Messaging for Encrypted {{CRDTs}}},
  author = {Kleppmann, Martin},
  year = {2019},
  month = may,
  address = {{Kaiserslautern, Germany}},
  url = {https://martin.kleppmann.com/2019/05/15/encrypted-crdts.html},
  urldate = {2021-07-15},
  abstract = {Secure messaging apps like WhatsApp, Signal, and iMessage have brought end-to-end encryption to over 1 billion users. The protocols underlying these apps provide much stronger security properties than earlier encryption systems such as PGP/GnuPG. This makes them an interesting basis for implementing CRDT-based data systems with end-to-end security: if we simply send all the CRDT operations or state updates via a secure messaging protocol, we inherit its strong security properties. However, there are lots of subtleties about the guarantees provided by secure messaging protocols: in particular, the properties that hold for communication between two parties often don't easily generalise to groups of more than two participants. This talk will summarise the current state of research in secure group messaging, and discuss how we can bring this work into the world of CRDTs.}
}

@article{kokocinskiMixingEventualStrong2021,
  title = {On {{Mixing Eventual}} and {{Strong Consistency}}: {{Acute Cloud Types}}},
  shorttitle = {On {{Mixing Eventual}} and {{Strong Consistency}}},
  author = {Kokocinski, Maciej and Kobus, Tadeusz and Wojciechowski, Pawe Tomasz},
  year = {2021},
  journal = {IEEE Transactions on Parallel and Distributed Systems},
  pages = {1--1},
  issn = {1558-2183},
  doi = {10.1109/TPDS.2021.3090318},
  abstract = {In this article we study the properties of distributed systems that mix eventual and strong consistency. We formalize such systems through acute cloud types (ACTs), abstractions similar to conflict-free replicated data types (CRDTs), which by default work in a highly available, eventually consistent fashion, but which also feature strongly consistent operations for tasks which require global agreement. Unlike other mixed-consistency solutions, ACTs can rely on efficient quorum-based protocols, such as Paxos. Hence, ACTs gracefully tolerate machine and network failures also for the strongly consistent operations. We formally study ACTs and demonstrate phenomena which are neither present in purely eventually consistent nor strongly consistent systems. In particular, we identify temporary operation reordering, which implies interim disagreement between replicas on the relative order in which the client requests were executed. When not handled carefully, this phenomenon may lead to undesired anomalies, including circular causality. We prove an impossibility result which states that temporary operation reordering is unavoidable in mixed-consistency systems with sufficiently complex semantics. Our result is startling, because it shows that apparent strengthening of the semantics of a system (by introducing strongly consistent operations to an eventually consistent system) results in the weakening of the guarantees on the eventually consistent operations.},
  keywords = {ACT,acute cloud types,Data structures,eventual consistency,fault-tolerance,mixed consistency,Protocols,Reactive power,Scalability,Semantics,Servers,Synchronization}
}

@inproceedings{kwiatkowskaPossibleGuaranteedConcurrency1995,
  title = {Possible and {{Guaranteed Concurrency}} in {{CSP}}},
  booktitle = {Structures in {{Concurrency Theory}}},
  author = {Kwiatkowska, Marta and Phillips, Iain},
  editor = {Desel, J{\"o}rg},
  year = {1995},
  series = {Workshops in {{Computing}}},
  pages = {220--235},
  publisher = {{Springer}},
  address = {{London}},
  doi = {10.1007/978-1-4471-3078-9_15},
  abstract = {As part of an effort to give a ``truly concurrent'' semantics to process algebra, we propose a framework of refinements of the failures model for CSP with concurrency, conflict and causality relations on traces. These relations are defined by induction over syntax of CSP processes. We study in detail two new semantics: the possible concurrency (where two traces are said to be concurrent if they may be observations of the same concurrent run) and the possible conflict (two traces are said to be in conflict if they may be observations of two different runs). The guaranteed concurrency is obtained from the possible conflict semantics. Although the expansion law is necessarily weakened to an inequality, we show that most of the CSP laws are preserved, the exception being the idempotency of choice for the possible conflict refinement. Finally, we show that our semantics is well-founded by demonstrating a strong connection with the existing event structures semantics for CSP. The latter results show that, in a certain sense, concurrency distinctions can be made at the level of syntax, without resorting to reasoning about event occurrences.},
  isbn = {978-1-4471-3078-9},
  langid = {english},
  keywords = {Communicate Sequential Process,Conflict Relation,Event Structure,Process Algebra,Trace Theory}
}

@article{lamportTemporalLogicActions1994,
  title = {The Temporal Logic of Actions},
  author = {Lamport, Leslie},
  year = {1994},
  month = may,
  journal = {ACM Transactions on Programming Languages and Systems},
  volume = {16},
  number = {3},
  pages = {872--923},
  issn = {0164-0925},
  doi = {10.1145/177492.177726},
  abstract = {The temporal logic of actions (TLA) is a logic for specifying and reasoning about concurrent systems. Systems and their properties are represented in the same logic, so the assertion that a system meets its specification and the assertion that one system implements another are both expressed by logical implication. TLA is very simple; its syntax and complete formal semantics are summarized in about a page. Yet, TLA is not just a logician's toy; it is extremely powerful, both in principle and in practice. This report introduces TLA and describes how it is used to specify and verify concurrent algorithms. The use of TLA to specify and reason about open systems will be described elsewhere.},
  keywords = {concurrent programming,liveness properties,safety properties}
}

@article{Ma2020Writing,
  title = {Writing in Sign: {{Code}} as the next Contract Language? \ding{45}Ô∏è ‚è≠ üíª},
  author = {Ma, Megan},
  year = {2020-08-14, 2020-8-14},
  journal = {MIT Computational Law Report},
  url = {https://law.mit.edu/pub/writinginsign},
  abstract = {The use of formal logic for governance has a rich ancestry. From Liebniz to Boole, mathematical notation was conceivably dialogic; capable of expression and construction of arguments. With the rise of artificial legal intelligence, computable contracts \textendash{} and more broadly, computable law \textendash{} are making a powerful return. Contracts may be represented as computer data with terms made `machine-readable' through a process of conversion: from descriptive natural language to consonant computer instruction. Conditions of agreements are not explained but listed as structured data records. However, despite the capacity to express contracts in an alternative computable form, no means exist for interpreting the code. Rather, the interpretation of contractual obligations is perceived as irrelevant. Should digital data inscription and processing be considered a form of legal writing? If so, would it change the character of law? This paper considers the conundrum: what is the significance of the medium in contract drafting? The paper is, therefore, a thought experiment on the translation of text to numbers by unpacking several formal programming languages used in computable contracts. In identifying the logic of these languages, the paper studies methods of legal writing. The hypothesis is that, by analyzing the components of both legal and programming languages, we can develop a richer dialogue on the sociological implications of translating law into algorithmic form. Furthermore, we can begin to consider what contextual information would be required to `interpret' algorithmic contractual language.}
}

@phdthesis{millerRobustCompositionUnified2006,
  title = {Robust {{Composition}}: {{Towards}} a {{Unified Approach}} to {{Access Control}} and {{Concurrency Control}}},
  author = {Miller, Mark Samuel},
  year = {2006},
  month = may,
  address = {{Baltimore, Maryland, USA}},
  url = {http://www.erights.org/talks/thesis/markm-thesis.pdf},
  urldate = {2021-06-27},
  school = {Johns Hopkins University}
}

@inproceedings{netterRefiningPatternBasedReference2010,
  title = {Refining the {{Pattern-Based Reference Model}} for {{Electronic Invoices}} by {{Incorporating Threats}}},
  booktitle = {2010 {{International Conference}} on {{Availability}}, {{Reliability}} and {{Security}}},
  author = {Netter, Michael and Fernandez, Eduardo B. and Pernul, G{\"u}nther},
  year = {2010},
  month = feb,
  pages = {560--564},
  doi = {10.1109/ARES.2010.50},
  abstract = {Almost every company needs to process invoices to either claim money from their customers or to pay for products or services. Although companies are allowed to electronically process their invoices, most of them still rely on the paper-based invoice process. Within this paper we built upon existing work to develop a methodology for defining a reference model for the electronic invoice based on security patterns. This paper identifies threats of the e-invoice process in order to create a context for the security problem, which allows us to refine our methodology.},
  keywords = {Availability,Companies,Computer science,Computer security,Data security,electronic invoice,Information security,Information systems,misuse activities,Pattern analysis,Refining,Reliability engineering,security patterns,threat identification}
}

@misc{NextGenerationDataSharing2019,
  title = {The {{Next Generation}} of {{Data-Sharing}} in {{Financial Services}}: {{Using Privacy Enhancing Techniques}} to {{Unlock New Value}}},
  year = {2019},
  month = sep,
  publisher = {{World Economic Forum}},
  abstract = {Homomorphic Encryption},
  langid = {english}
}

@inproceedings{nigamFormalSecurityVerification2019,
  title = {Formal {{Security Verification}} of {{Industry}} 4.0 {{Applications}}},
  booktitle = {2019 24th {{IEEE International Conference}} on {{Emerging Technologies}} and {{Factory Automation}} ({{ETFA}})},
  author = {Nigam, Vivek and Talcott, Carolyn},
  year = {2019},
  month = sep,
  pages = {1043--1050},
  issn = {1946-0759},
  doi = {10.1109/ETFA.2019.8869428},
  abstract = {Without appropriate counter-measures, cyber-attacks can exploit the increased system connectivity provided by Industry 4.0 (I4.0) to cause catastrophic events, by, e.g., injecting or tampering with messages. The solution supported by standards, such as, OPC-UA, is to sign or encrypt messages. However, given the limited resources of devices, instead of encrypting all messages in the network, it is better to encrypt only the messages that if tampered with or injected, could lead to undesired configurations. This paper describes the use of formal verification to analyse the security of I4.0 applications. We formalize in Rewriting Logic, I4.0 applications and systems, i.e., networked sets of devices, and a symbolic intruder model. Our formalization can be executed by the tool Maude to automate such security analysis, e.g., determine which messages are sufficient to sign in order avoid injection and tampering attacks.},
  keywords = {Cryptography,Grippers,Industries,Production facilities,Standards,Tools}
}

@misc{OpenIDConnectOpenID2011,
  title = {{{OpenID Connect}} | {{OpenID}}},
  year = {2011},
  month = aug,
  url = {https://openid.net/connect/},
  urldate = {2021-10-25},
  abstract = {OpenID Connect page},
  langid = {american}
}

@article{pereiraNetworkInformationSecurity2017,
  title = {Network and Information Security Challenges within {{Industry}} 4.0 Paradigm},
  author = {Pereira, T. and Barreto, L. and Amaral, A.},
  year = {2017},
  month = jan,
  journal = {Procedia Manufacturing},
  series = {Manufacturing {{Engineering Society International Conference}} 2017, {{MESIC}} 2017, 28-30 {{June}} 2017, {{Vigo}} ({{Pontevedra}}), {{Spain}}},
  volume = {13},
  pages = {1253--1260},
  issn = {2351-9789},
  doi = {10.1016/j.promfg.2017.09.047},
  abstract = {Currently Information and Communication Technologies (ICT) support most of the industrial manufacturing processes. The IT revolution has brought an important transformation in organizations with high impacts, which are comparable to the mechanization and electricity brought in the first and second industrial revolution. This evolvement has promoted the emergence of cloud-based systems, the Internet of Things (IoT), Big Data, Industry 4.0, BYOD (Bring Your Own Device) and CYOD (Choose Your Own Device) trends. However, new technological solutions always carry security vulnerabilities, which most of time reveal unexpected risks. In fact, with increasing reliance on technology to gain competitive advantage, security issues have been one of the most critical and challenging requirements for conducting successful business. In this paper, it is highlighted some reflections regarding the challenges of Industry 4.0 emphasizing the security issues, towards raising awareness for security good practices within Industry 4.0.},
  langid = {english},
  keywords = {Communication Technologies (ICT),Industry 4.0,Information,Security Challenges,Security Incidents}
}

@misc{presslerTLAPracticeTheoryPart2017,
  title = {{{TLA}}+ in {{Practice}} and {{Theory}}{$<$}br/{$>$}{{Part}} 3: {{The}} ({{Temporal}}) {{Logic}} of {{Actions}}},
  shorttitle = {{{TLA}}+ in {{Practice}} and {{Theory Part}} 3},
  author = {Pressler, Ron},
  year = {2017},
  month = jun,
  journal = {Ron Pressler},
  url = {https://pron.github.io/posts/tlaplus_part3},
  urldate = {2022-10-04},
  abstract = {TLA, the Temporal Logic of Actions is the core of TLA+. It is a temporal logic that minimizes the use of temporal reasoning in favor of more ordinary mathematics. It is a general mathematical framework for describing and reasoning about algorithms and systems.}
}

@misc{ProofMarkSystemTechnical2007,
  title = {{{ProofMark System Technical Overview}}},
  year = {2007},
  month = jul,
  publisher = {{ProofSpace}},
  url = {http://fios.com/proofmarksystemtech.pdf},
  urldate = {2021-11-01},
  abstract = {The ProofSpace system is designed to verify to a high degree of trustworthiness the ``time existence of data.'' To accomplish this, it employs a patented transient key technology to irrefutably link a given set of data (a digital file, for example) to a given interval of time. The linkage is embodied in a ProofMark, which is a certificate containing multiple cryptographic mechanisms that attest to the existence of the original data within the stated time interval. The ProofSpace solution is most easily understood by beginning with a description of the fundamental conceptual building blocks of the system. We will then provide a functional description of the current ProofSpace implementation, followed by a hypothetical scenario illustrating how ProofMarks might be used with an E-Mail Archiving/eDiscovery solution, and  conclude with a discussion of alignment with relevant industry standards for time and date stamping and file authentication.}
}

@misc{raevuoriBaswarePersonalData2020,
  title = {Basware {{Personal Data Processing Appendix}}},
  author = {Raevuori, Antti},
  year = {2020},
  month = mar,
  url = {https://www.basware.com/Basware/files/c6/c69a3db2-8e57-460a-9631-c19572a0c9ba.pdf},
  urldate = {2021-07-02}
}

@incollection{raynalLogicalInstantaneityCausal2000,
  title = {Logical {{Instantaneity}} and {{Causal Order}}: {{Two}} ``{{First Class}}'' {{Communication Modes}} for {{Parallel Computing}}},
  shorttitle = {Logical {{Instantaneity}} and {{Causal Order}}},
  booktitle = {Euro-{{Par}} 2000 {{Parallel Processing}}},
  author = {Raynal, Michel},
  editor = {Goos, Gerhard and Hartmanis, Juris and {van Leeuwen}, Jan and Bode, Arndt and Ludwig, Thomas and Karl, Wolfgang and Wism{\"u}ller, Roland},
  year = {2000},
  volume = {1900},
  pages = {35--42},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/3-540-44520-X_4},
  abstract = {This paper focuses on two communication modes, namely Logically Instantaneity (li) and Causal Order (co). These communication modes address two different levels of quality of service in message delivery. li means that it is possible to timestamp communication events with integers in such a way that (1) timestamps increase within each process and (2) the sending and the delivery events associated with each message have the same timestamp. So, there is a logical time frame in which for each message, the send event and the corresponding delivery events occur simultaneously. co means that when a process delivers a message m, its delivery occurs in a context where the receiving process knows all the causal past of m. Actually, li is a property strictly stronger than co.},
  isbn = {978-3-540-67956-1 978-3-540-44520-3},
  langid = {english}
}

@misc{rixhamRDFNamedGraphs2012,
  type = {Blog},
  title = {{{RDF}}: {{Named Graphs}} -vs- {{Graph Literals}} \textendash{} Webr3.Org},
  shorttitle = {{{RDF}}},
  author = {Rixham, Nathan},
  year = {2012},
  month = mar,
  url = {http://webr3.org/blog/semantic-web/rdf-named-graphs-vs-graph-literals/},
  urldate = {2022-01-19},
  abstract = {An overview of Named Graphs and Graph Literals and the distinctions between them.}
}

@book{roscoeUnderstandingConcurrentSystems2010,
  title = {Understanding {{Concurrent Systems}}},
  author = {Roscoe, A. W.},
  year = {2010},
  month = oct,
  publisher = {{Springer Science \& Business Media}},
  abstract = {CSP notation has been used extensively for teaching and applying concurrency theory, ever since the publication of the text Communicating Sequential Processes by C.A.R. Hoare in 1985. Both a programming language and a specification language, the theory of CSP helps users to understand concurrent systems, and to decide whether a program meets its specification. As a member of the family of process algebras, the concepts of communication and interaction are presented in an algebraic style. An invaluable reference on the state of the art in CSP, Understanding Concurrent Systems also serves as a comprehensive introduction to the field, in addition to providing material for a number of more advanced courses. A first point of reference for anyone wanting to use CSP or learn about its theory, the book also introduces other views of concurrency, using CSP to model and explain these. The text is fully integrated with CSP-based tools such as FDR, and describes how to create new tools based on FDR. Most of the book relies on no theoretical background other than a basic knowledge of sets and sequences. Sophisticated mathematical arguments are avoided whenever possible. Topics and features: presents a comprehensive introduction to CSP; discusses the latest advances in CSP, covering topics of operational semantics, denotational models, finite observation models and infinite-behaviour models, and algebraic semantics; explores the practical application of CSP, including timed modelling, discrete modelling, parameterised verifications and the state explosion problem, and advanced topics in the use of FDR; examines the ability of CSP to describe and enable reasoning about parallel systems modelled in other paradigms; covers a broad variety of concurrent systems, including combinatorial, timed, priority-based, mobile, shared variable, statecharts, buffered and asynchronous systems; contains exercises and case studies to support the text; supplies further tools and information at the associated website: http://www.comlab.ox.ac.uk/ucs/. From undergraduate students of computer science in need of an introduction to the area, to researchers and practitioners desiring a more in-depth understanding of theory and practice of concurrent systems, this broad-ranging text/reference is essential reading for anyone interested in Hoare's CSP.},
  googlebooks = {SZCWr4bCCtcC},
  isbn = {978-1-84882-258-0},
  langid = {english},
  keywords = {Computers / Operating Systems / General,Computers / Programming / General}
}

@techreport{Sabadello:21:DI,
  type = {{{W3C}} Proposed Reccommendation},
  title = {Decentralized Identifiers ({{DIDs}}) v1.0},
  author = {Sabadello, Markus and Sporny, Manu and Reed, Drummond and Guy, Amy},
  year = {2021},
  month = aug,
  institution = {{W3C}},
  bibsource = {https://w2.syronex.com/jmr/w3c-biblio}
}

@techreport{sambraWebID2014,
  type = {{{W3C Editor}}'s {{Draft}}},
  title = {{{WebID}} 1.0},
  author = {Sambra, Andrei and Story, Henry and {Berners-Lee}, Tim},
  year = {2014},
  month = mar,
  institution = {{W3C}},
  url = {https://www.w3.org/2005/Incubator/webid/spec/identity/},
  urldate = {2021-10-25},
  abstract = {A global distributed Social Web requires that each person be able to control their identity, that this identity be linkable across sites - placing each person in a Web of relationships - and that it be possible to authenticate globally with such identities. This specification outlines a simple universal identification mechanism that is distributed, openly extensible, improves privacy, security and control over how each person can identify themselves in order to allow fine grained access control to their information on the Web. It does this by applying the best practices of Web Architecture whilst building on well established widely deployed protocols and standards including HTML, URIs, HTTP, and RDF Semantics.}
}

@inproceedings{shapiroConflictFreeReplicatedData2011,
  title = {Conflict-{{Free Replicated Data Types}}},
  booktitle = {Stabilization, {{Safety}}, and {{Security}} of {{Distributed Systems}}},
  author = {Shapiro, Marc and Pregui{\c c}a, Nuno and Baquero, Carlos and Zawirski, Marek},
  editor = {D{\'e}fago, Xavier and Petit, Franck and Villain, Vincent},
  year = {2011},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {386--400},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-24550-3_29},
  abstract = {Replicating data under Eventual Consistency (EC) allows any replica to accept updates without remote synchronisation. This ensures performance and scalability in large-scale distributed systems (e.g., clouds). However, published EC approaches are ad-hoc and error-prone. Under a formal Strong Eventual Consistency (SEC) model, we study sufficient conditions for convergence. A data type that satisfies these conditions is called a Conflict-free Replicated Data Type (CRDT). Replicas of any CRDT are guaranteed to converge in a self-stabilising manner, despite any number of failures. This paper formalises two popular approaches (state- and operation-based) and their relevant sufficient conditions. We study a number of useful CRDTs, such as sets with clean semantics, supporting both add and remove operations, and consider in depth the more complex Graph data type. CRDT types can be composed to develop large-scale distributed applications, and have interesting theoretical properties.},
  isbn = {978-3-642-24550-3},
  langid = {english},
  keywords = {Eventual Consistency,Large-Scale Distributed Systems,Replicated Shared Objects}
}

@inproceedings{souagSecurityOntologySecurity2015,
  title = {A {{Security Ontology}} for {{Security Requirements Elicitation}}},
  booktitle = {Engineering {{Secure Software}} and {{Systems}}},
  author = {Souag, Amina and Salinesi, Camille and Mazo, Ra{\'u}l and {Comyn-Wattiau}, Isabelle},
  editor = {Piessens, Frank and Caballero, Juan and Bielova, Nataliia},
  year = {2015},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {157--177},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-15618-7_13},
  abstract = {Security is an important issue that needs to be taken into account at all stages of information system development, including early requirements elicitation. Early analysis of security makes it possible to predict threats and their impacts and define adequate security requirements before the system is in place. Security requirements are difficult to elicit, analyze, and manage. The fact that analysts' knowledge about security is often tacit makes the task of security requirements elicitation even harder. Ontologies are known for being a good way to formalize knowledge. Ontologies, in particular, have been proved useful to support reusability. Requirements engineering based on predefined ontologies can make the job of requirement engineering much easier and faster. However, this very much depends on the quality of the ontology that is used. Some security ontologies for security requirements have been proposed in the literature. None of them stands out as complete. This paper presents a core and generic security ontology for security requirements engineering. Its core and generic status is attained thanks to its coverage of wide and high-level security concepts and relationships. We implemented the ontology and developed an interactive environment to facilitate the use of the ontology during the security requirements engineering process. The proposed security ontology was evaluated by checking its validity and completeness compared to other ontologies. Moreover, a controlled experiment with end-users was performed to evaluate its usability.},
  isbn = {978-3-319-15618-7},
  langid = {english},
  keywords = {concepts,elicitation,ontology,Security,security requirements}
}

@inproceedings{svarovskyMldRealtimeInformation2021,
  title = {M-Ld: {{Realtime Information Sharing}} with {{RDF}}},
  shorttitle = {M-Ld},
  booktitle = {Joint {{Proceedings}} of the {{Semantics}} Co-Located Events: {{Poster}}\&{{Demo}} Track and {{Workshop}} on {{Ontology-Driven Conceptual Modelling}} of {{Digital Twins}} Co-Located with {{Semantics}} 2021},
  author = {Svarovsky, George},
  year = {2021},
  month = sep,
  volume = {Semantics Compound Volume 2021},
  publisher = {{CEUR Workshop Proceedings}},
  address = {{Amsterdam, NL}},
  abstract = {Users of information systems increasingly expect information to be available to edit from multiple devices and by multiple users, online and offline. Strategies exist for shared data types with strong eventual consistency guarantees. These can be complex and fault-prone to implement de novo for application data, and library implementations do not present standard APIs. To improve data interoperability, portabil-ity and extensibility, these strategies can be applied to a standard and self-describing data format, RDF. We introduce m-ld, a component providing eventual consistency for RDF data, showing how it can be used to create a collaborative message board program.},
  copyright = {All rights reserved}
}

@article{syedUCOUnifiedCybersecurity2016,
  title = {{{UCO}}: {{A Unified Cybersecurity Ontology}}},
  shorttitle = {{{UCO}}},
  author = {Syed, Zareen and Padia, Ankur and Finin, Tim and Mathews, Lisa and Joshi, Anupam},
  year = {2016},
  month = feb,
  publisher = {{AAAI Press}},
  doi = {10.13016/M2862BG1V},
  abstract = {In this paper we describe the Unified Cybersecurity Ontology (UCO) that is intended to support information integration and cyber situational awareness in cybersecurity systems. The ontology incorporates and integrates heterogeneous data and knowledge schemas from different cybersecurity systems and most commonly used cybersecurity standards for information sharing and exchange. The UCO ontology has also been mapped to a number of existing cybersecurity ontologies as well as concepts in the Linked Open Data cloud. Similar to DBpedia which serves as the core for general knowledge in Linked Open Data cloud, we envision UCO to serve as the core for cybersecurity domain, which would evolve and grow with the passage of time with additional cybersecurity data sets as they become available. We also present a prototype system and concrete use cases supported by the UCO ontology. To the best of our knowledge, this is the first cybersecurity ontology that has been mapped to general world ontologies to support broader and diverse security use cases. We compare the resulting ontology with previous efforts, discuss its strengths and limitations, and describe potential future work directions.},
  copyright = {This item is likely protected under Title 17 of the U.S. Copyright Law. Unless on a Creative Commons license, for uses protected by Copyright Law, contact the copyright holder or the author.},
  langid = {american},
  annotation = {Accepted: 2018-10-31T17:48:05Z}
}

@misc{teixeiraDecentralisedAccessControl2018,
  title = {Decentralised {{Access Control}} in {{CRDTs}} {$\cdot$} {{Issue}} \#8 {$\cdot$} Protocol/Research},
  author = {Teixeira, Pedro},
  year = {2018},
  month = may,
  journal = {GitHub},
  url = {https://github.com/protocol/research/issues/8},
  urldate = {2021-09-27},
  abstract = {Using a CRDT, users can collaborate in real-time editing of a shared document over a loosely connected P2P network. Each user will have a replica of the shared document and they will send each other messages signifying updates to the state (either in the form of operations, whole states or deltas). While CRDTs already make this possible, certain useful capabilities do not exist yet. For example, the owner of a document might want to collaborate with other uses, but still be able to maintain control of who can read or write to this document. Not only does the user want to protect their local replica but, in order to maintain consistency across peers, they also want to inform the other replicas of which users are allowed to do what. Besides having the power to adding permissions to users in all of the replicas, they might want to be able to remove these permissions and be able to also propagate this to the other replicas. Besides read and write access, this user may also want to delegate this power to other users, so that they also can become administrators of permissions for this given replica. Any of these permissions should also be revocable in the future. The initial owner will create a message describing this permission and propagate it to all the other users. When knowing this information, replica of user B will start making local changes, and those changes will be propagated to other replicas. If, while user B is propagating the replica, user A revokes this permission, how can this be accomplished in a way that is secure and that still guarantees SEC?},
  langid = {english}
}

@misc{wardScalabilityMonitoringDebugging,
  title = {On the {{Scalability}} of {{Monitoring}} and {{Debugging Distributed Computations}}: {{Vector-Clock Size}}},
  shorttitle = {On the {{Scalability}} of {{Monitoring}} and {{Debugging Distributed Computations}}},
  author = {Ward, Paul A. S.},
  abstract = {The vector-clock size necessary to characterize causality in an arbitrary distributed computation is equal to the number of processes in that computation. However, in practice the vector-clock size necessary may be much smaller. The vector-clock size is not strictly bounded by the number of processes, but rather by the dimension of the partial order induced by the computation. While the dimension theoretically can be as large as the number of processes, in practice we have found it to be much smaller. In this paper we quantify exactly how small the dimension, and hence the vector-clock size required, is over a range of typical distributed computations. We have found that typical distributed computations, with as many as 300 processes, have dimension less than 10. In order to achieve this quantification we developed several novel theorems and algorithms which we also describe.}
}

@article{yaacoubRoboticsCyberSecurity2021,
  title = {Robotics Cyber Security: Vulnerabilities, Attacks, Countermeasures, and Recommendations},
  shorttitle = {Robotics Cyber Security},
  author = {Yaacoub, Jean-Paul A. and Noura, Hassan N. and Salman, Ola and Chehab, Ali},
  year = {2021},
  month = mar,
  journal = {International Journal of Information Security},
  issn = {1615-5270},
  doi = {10.1007/s10207-021-00545-8},
  abstract = {The recent digital revolution led robots to become integrated more than ever into different domains such as agricultural, medical, industrial, military, police (law enforcement), and logistics. Robots are devoted to serve, facilitate, and enhance the human life. However, many incidents have been occurring, leading to serious injuries and devastating impacts such as the unnecessary loss of human lives. Unintended accidents will always take place, but the ones caused by malicious attacks represent a very challenging issue. This includes maliciously hijacking and controlling robots and causing serious economic and financial losses. This paper reviews the main security vulnerabilities, threats, risks, and their impacts, and the main security attacks within the robotics domain. In this context, different approaches and recommendations are presented in order to enhance and improve the security level of robotic systems such as multi-factor device/user authentication schemes, in addition to multi-factor cryptographic algorithms. We also review the recently presented security solutions for robotic systems.},
  langid = {english}
}

@misc{zhangMETModelCheckingDriven2022,
  title = {{{MET}}: {{Model Checking-Driven Explorative Testing}} of {{CRDT Designs}} and {{Implementations}}},
  shorttitle = {{{MET}}},
  author = {Zhang, Yuqi and Huang, Yu and Wei, Hengfeng and Ma, Xiaoxing},
  year = {2022},
  month = apr,
  number = {arXiv:2204.14129},
  eprint = {2204.14129},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2204.14129},
  abstract = {Internet-scale distributed systems often replicate data at multiple geographic locations to provide low latency and high availability. The Conflict-free Replicated Data Type (CRDT) is a framework that provides a principled approach to maintaining eventual consistency among data replicas. CRDTs have been notoriously difficult to design and implement correctly. Subtle deep bugs lie in the complex and tedious handling of all possible cases of conflicting data updates. We argue that the CRDT design should be formally specified and model-checked to uncover deep bugs. The implementation further needs to be systematically tested. On the one hand, the testing needs to inherit the exhaustive nature of the model checking and ensures the coverage of testing. On the other hand, the testing is expected to find coding errors which cannot be detected by design level verification. Towards the challenges above, we propose the Model Checking-driven Explorative Testing (MET) framework. At the design level, MET uses TLA+ to specify and model check CRDT designs. At the implementation level, MET conducts model checking-driven explorative testing, in the sense that the test cases are automatically generated from the model checking traces. The system execution is controlled to proceed deterministically, following the model checking trace. The explorative testing systematically controls and permutes all nondeterministic message reorderings. We apply MET in our practical development of CRDTs. The bugs in both designs and implementations of CRDTs are found. As for bugs which can be found by traditional testing techniques, MET greatly reduces the cost of fixing the bugs. Moreover, MET can find subtle deep bugs which cannot be found by existing techniques at a reasonable cost. We further discuss how MET provides us with sufficient confidence in the correctness of our CRDT designs and implementations.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Distributed; Parallel; and Cluster Computing,Computer Science - Software Engineering}
}

@misc{zimmermannWhyWrotePGP1999,
  type = {Essay},
  title = {Why {{I Wrote PGP}}},
  author = {Zimmermann, Philip},
  year = {1999},
  url = {http://www.philzimmermann.com/EN/essays/WhyIWrotePGP.html},
  urldate = {2021-06-22}
}

